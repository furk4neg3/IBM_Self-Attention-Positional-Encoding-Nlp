# self-attention-positional-encoding-nlp
A comprehensive lab exploring self-attention and positional encoding techniques in NLP, with code implementations for tokenization, translation, and similarity measures. This project was completed as part of IBM's deep learning course.
